{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ee6755a",
   "metadata": {},
   "source": [
    "### Note: All synIDS are specific to the 2025 DREAM Olfactory Mixtures Prediction Challenge Final Round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ee703c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import synapseclient\n",
    "\n",
    "SUBMISSION_VIEWS = {\n",
    "    \"Task 1\": \"syn68879001\",\n",
    "    \"Task 2\": \"syn68878940\"\n",
    "}\n",
    "\n",
    "# Mapping for goldstandard and submission views by task\n",
    "GOLDSTANDARD_SYNIDS = {1: \"syn68736530\", 2: \"syn68736533\"}\n",
    "SUBMISSION_VIEWS = {\"Task 1\": \"syn68879001\", \"Task 2\": \"syn68878940\"}\n",
    "INDEX_COL = \"stimulus\"\n",
    "\n",
    "# Synapse login\n",
    "syn = synapseclient.Synapse()\n",
    "syn.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869268f1",
   "metadata": {},
   "source": [
    "## Functions to Extract ground truth, submissions, and their file data from Synapse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "35b24ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_goldstandard(syn, task):\n",
    "    gold_synid = GOLDSTANDARD_SYNIDS[task]\n",
    "    file_entity = syn.get(gold_synid, downloadFile=True)\n",
    "    file_path = file_entity.path\n",
    "    gold_df = pd.read_csv(file_path)\n",
    "    return gold_df\n",
    "    \n",
    "def load_team_predictions(syn, submissions_df):\n",
    "    team_dfs = []\n",
    "    # No handling of the submission that's not recorded in the submission table \n",
    "    # for task 2 required given the late submission is not in the top 2 or 3\n",
    "    for _, row in submissions_df.iterrows():\n",
    "        team_id = row['submitterid']\n",
    "        sub_id = row['id']\n",
    "        file_path = syn.getSubmission(sub_id)['filePath']\n",
    "        df = pd.read_csv(file_path)\n",
    "        df = df.sort_values(INDEX_COL).reset_index(drop=True)\n",
    "        feature_cols = [col for col in df.columns if col != INDEX_COL]\n",
    "        rename_dict = {col: f\"team_{team_id}_{col}\" for col in feature_cols}\n",
    "        df = df.rename(columns=rename_dict)\n",
    "        df = df[[INDEX_COL] + list(rename_dict.values())]\n",
    "        team_dfs.append(df)\n",
    "    merged_df = team_dfs[0]\n",
    "    for df in team_dfs[1:]:\n",
    "        merged_df = pd.merge(merged_df, df, on=INDEX_COL, how='outer')\n",
    "    return merged_df\n",
    "\n",
    "def select_final_round_submissions(\n",
    "    syn: synapseclient.Synapse, subview_id: str, evaluation_id: str\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Get final round submissions from synapse tables that include all submissions for both rounds.\n",
    "    Outputs a final averaged rank and sorted leaderboard.\n",
    "    Only submissions from the specified evaluation are considered.\n",
    "    For each submitter, but one team, only the submission closest to August 8, 2025 is kept.\n",
    "    If any of the IDs [9756929, 9756930, 9756939, 9756938, 9756943, 9756942] are present,\n",
    "    keep only 9756929 if present, otherwise keep only 9756930 if present, and remove the rest.\n",
    "    Also manually add the permitted late submission for Task 2.\n",
    "    \"\"\"\n",
    "\n",
    "    query = (\n",
    "        f\"SELECT id, pearson_correlation, cosine, createdOn, submitterid FROM {subview_id} \"\n",
    "        f\"WHERE score_status = 'SCORED' \"\n",
    "    )  # query_df should have columns: 'id' and 'submitterid'\n",
    "    submissions = syn.tableQuery(query).asDataFrame()\n",
    "\n",
    "    # Special handling for the specified IDs\n",
    "    replace_ids = [9756929, 9756930, 9756939, 9756938, 9756943, 9756942]\n",
    "    present_ids = [rid for rid in replace_ids if rid in submissions['id'].values]\n",
    "    if present_ids:\n",
    "        if 9756929 in present_ids:\n",
    "            submissions = submissions[~submissions['id'].isin(replace_ids) | (submissions['id'] == 9756929)]\n",
    "        elif 9756930 in present_ids:\n",
    "            submissions = submissions[~submissions['id'].isin(replace_ids) | (submissions['id'] == 9756930)]\n",
    "        else:\n",
    "            submissions = submissions[~submissions['id'].isin(replace_ids)]\n",
    "\n",
    "    # Only add late submission for Task 2\n",
    "    if \"Task 2\" in evaluation_id or subview_id == SUBMISSION_VIEWS[\"Task 2\"]:\n",
    "        entity = syn.get(\"syn68843729\", downloadFile=False)\n",
    "        late_row = {\n",
    "            \"submitterid\": entity.createdBy,\n",
    "            \"id\": \"syn68843729\",\n",
    "            \"pearson_correlation\": 0.6668633229642209,\n",
    "            \"cosine\": 0.22813314634185586,\n",
    "            \"createdOn\": 1754692655346,\n",
    "            \"createdOn_diff\": 4943654\n",
    "        }\n",
    "        submissions = pd.concat([submissions, pd.DataFrame([late_row])], ignore_index=True)\n",
    "\n",
    "    # Find the submission closest to August 8, 2025 for each submitter\n",
    "    target_date = int(pd.Timestamp(\"2025-08-08T23:59:59Z\").timestamp() * 1000)\n",
    "    submissions['createdOn_diff'] = np.abs(submissions['createdOn'] - target_date)\n",
    "    submissions = submissions.sort_values(['submitterid', 'createdOn_diff'])\n",
    "    submissions = submissions.groupby('submitterid', as_index=False).first()\n",
    "\n",
    "    submissions['pearson_rank'] = submissions['pearson_correlation'].rank(\n",
    "        ascending=False, method=\"min\", na_option='bottom')\n",
    "    submissions['cosine_rank'] = submissions['cosine'].rank(\n",
    "        ascending=True, method=\"min\", na_option='bottom')\n",
    "    submissions['final_rank'] = (\n",
    "        submissions['pearson_rank'] + submissions['cosine_rank']) / 2\n",
    "\n",
    "    # Select the top 3 ranked submissions for future bootstrapping\n",
    "    top_submissions = submissions.nsmallest(3, 'final_rank')\n",
    "\n",
    "    return submissions, top_submissions\n",
    "\n",
    "def split_merged_to_team_dfs(merged_df, gold_df, index_col=\"stimulus\"):\n",
    "    \"\"\"\n",
    "    Convert merged_df from load_team_predictions into\n",
    "    a dict of team_name -> dataframe with [index_col + gold attribute columns].\n",
    "    Ensures predictors align with gold_df columns.\n",
    "    \"\"\"\n",
    "    # attribute columns are everything except index_col\n",
    "    attr_cols = [c for c in gold_df.columns if c != index_col]\n",
    "    \n",
    "    team_dfs = {}\n",
    "    for col in merged_df.columns:\n",
    "        if col == index_col:\n",
    "            continue\n",
    "        \n",
    "        # Parse out team_id from column name \"team_<id>_<attr>\"\n",
    "        parts = col.split(\"_\", 2)  # split into 3 parts: [\"team\", \"id\", \"AttrName\"]\n",
    "        if len(parts) < 3:\n",
    "            raise ValueError(f\"Unexpected column format: {col}\")\n",
    "        team_id = parts[1]\n",
    "        attr_name = parts[2]\n",
    "        \n",
    "        # Initialize dataframe for this team\n",
    "        if team_id not in team_dfs:\n",
    "            team_dfs[team_id] = merged_df[[index_col, col]].rename(columns={col: attr_name})\n",
    "        else:\n",
    "            team_dfs[team_id] = team_dfs[team_id].merge(\n",
    "                merged_df[[index_col, col]].rename(columns={col: attr_name}),\n",
    "                on=index_col,\n",
    "                how=\"outer\"\n",
    "            )\n",
    "    \n",
    "    # Reorder each team_df to match gold_df attribute order\n",
    "    for team_id in team_dfs:\n",
    "        cols = [index_col] + attr_cols\n",
    "        team_dfs[team_id] = team_dfs[team_id][cols]\n",
    "    \n",
    "    return team_dfs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bebe56e",
   "metadata": {},
   "source": [
    "## Functions Applied in Ranking, Bootstrapping, and winner determination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "16f1524d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_on_rows(rows, gold_mat, team_mat):\n",
    "    \"\"\"Compute pearson and cosine between gold and team predictions on sampled rows.\"\"\"\n",
    "    g = gold_mat[rows, :].ravel()\n",
    "    t = team_mat[rows, :].ravel()\n",
    "    if np.std(t) == 0 or np.std(g) == 0:\n",
    "        return np.nan, np.nan\n",
    "    pearson, _ = pearsonr(g, t)\n",
    "    cosine = 1 - cosine_similarity([g], [t])[0,0]  # lower = better\n",
    "    return pearson, cosine\n",
    "\n",
    "def baseline_and_bootstrap(\n",
    "    gold_df,\n",
    "    team_dfs,\n",
    "    index_col=\"stimulus\",\n",
    "    sample_frac=1.0,\n",
    "    N=10000,\n",
    "    random_state=None\n",
    "):\n",
    "    \"\"\"\n",
    "    gold_df: dataframe with gold labels (must include index_col and attribute columns)\n",
    "    team_dfs: dict[name -> dataframe] (each must include index_col and same attribute columns)\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    \n",
    "    # Automatically infer attribute columns (everything except the index_col)\n",
    "    attr_cols = [c for c in gold_df.columns if c != index_col]\n",
    "    if not attr_cols:\n",
    "        raise ValueError(\"No attribute columns found besides index_col.\")\n",
    "    \n",
    "    # Align to common IDs\n",
    "    gold_ids = gold_df[index_col].astype(str)\n",
    "    team_ids = [set(df[index_col].astype(str)) for df in team_dfs.values()]\n",
    "    common_ids_all = set(gold_ids).intersection(*team_ids)\n",
    "    if not common_ids_all:\n",
    "        raise ValueError(\"No overlapping stimuli across all teams.\")\n",
    "    \n",
    "    keep_gold = gold_df[index_col].astype(str).isin(common_ids_all)\n",
    "    gold_master = gold_df.loc[keep_gold, attr_cols].to_numpy()\n",
    "    order_ids = gold_df.loc[keep_gold, index_col].astype(str).tolist()\n",
    "    \n",
    "    team_mats = {}\n",
    "    for nm, df in team_dfs.items():\n",
    "        sub = df[df[index_col].astype(str).isin(common_ids_all)]\n",
    "        sub = sub.set_index(index_col).reindex(order_ids)\n",
    "        team_mats[nm] = sub[attr_cols].to_numpy()\n",
    "    \n",
    "    team_names = list(team_mats.keys())\n",
    "    n = gold_master.shape[0]\n",
    "    \n",
    "    # ==== BASELINE ====\n",
    "    base_metrics = []\n",
    "    for nm in team_names:\n",
    "        p, c = metrics_on_rows(np.arange(n), gold_master, team_mats[nm])\n",
    "        base_metrics.append([nm, p, c])\n",
    "    baseline_df = pd.DataFrame(base_metrics, columns=[\"team\",\"pearson\",\"cosine\"])\n",
    "    \n",
    "    baseline_df[\"rank_pearson\"] = baseline_df[\"pearson\"].rank(ascending=False, method=\"average\")\n",
    "    baseline_df[\"rank_cosine\"]  = baseline_df[\"cosine\"].rank(ascending=True,  method=\"average\")\n",
    "    baseline_df[\"average_rank\"] = (baseline_df[\"rank_pearson\"] + baseline_df[\"rank_cosine\"]) / 2\n",
    "    baseline_df = baseline_df.sort_values(\n",
    "        [\"average_rank\",\"rank_pearson\",\"rank_cosine\",\"pearson\",\"cosine\"],\n",
    "        ascending=[True,True,True,False,True]\n",
    "    )\n",
    "    \n",
    "    top2 = baseline_df[\"team\"].iloc[:2].tolist()\n",
    "    \n",
    "    # ==== BOOTSTRAP ====\n",
    "    B = max(1, round(n * sample_frac))\n",
    "    wins = 0\n",
    "    ties = 0\n",
    "    \n",
    "    for _ in range(N):\n",
    "        rows = rng.choice(n, size=B, replace=True)\n",
    "        met = {nm: metrics_on_rows(rows, gold_master, mat) for nm, mat in team_mats.items()}\n",
    "        pearsons = {nm: m[0] for nm, m in met.items()}\n",
    "        cosines  = {nm: m[1] for nm, m in met.items()}\n",
    "        \n",
    "        df_tmp = pd.DataFrame({\n",
    "            \"team\": team_names,\n",
    "            \"pearson\": [pearsons[nm] for nm in team_names],\n",
    "            \"cosine\": [cosines[nm] for nm in team_names]\n",
    "        })\n",
    "        df_tmp[\"rP\"] = df_tmp[\"pearson\"].rank(ascending=False, method=\"average\")\n",
    "        df_tmp[\"rC\"] = df_tmp[\"cosine\"].rank(ascending=True,  method=\"average\")\n",
    "        df_tmp[\"avg\"] = (df_tmp[\"rP\"] + df_tmp[\"rC\"]) / 2\n",
    "        avg_dict = df_tmp.set_index(\"team\")[\"avg\"].to_dict()\n",
    "        \n",
    "        a1, a2 = avg_dict[top2[0]], avg_dict[top2[1]]\n",
    "        if np.isnan(a1) or np.isnan(a2):\n",
    "            continue\n",
    "        if a1 < a2: \n",
    "            wins += 1\n",
    "        elif a1 == a2: \n",
    "            ties += 1\n",
    "    \n",
    "    p_win = (wins + 0.5 * ties) / N\n",
    "    BF_odds = (p_win + 1e-8) / (1 - p_win + 1e-8)\n",
    "    \n",
    "    return baseline_df, {\"p_win\": p_win, \"BF_odds\": BF_odds,\n",
    "                         \"N\": N, \"rows_per_draw\": B, \"sample_frac\": sample_frac}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2451fba2",
   "metadata": {},
   "source": [
    "## Task 1 Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bbd235",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading files: 100%|██████████| 3.91k/3.91k [00:00<00:00, 18.3kB/s, syn68879001]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded syn68879001 to /Users/mdiaz/.synapseCache/481/161875481/SYNAPSE_TABLE_QUERY_161875481.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading files: 100%|██████████| 3.91k/3.91k [00:00<00:00, 18.0kB/s, syn68879001]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading files:   0%|          | 0.00/2.72k [00:00<?, ?B/s, syn68878940]"
     ]
    }
   ],
   "source": [
    "subview_id = SUBMISSION_VIEWS[\n",
    "        f\"Task {1}\"]\n",
    "submissions_df = select_final_round_submissions(\n",
    "        syn, subview_id, \"Final Round DREAM Olfactory Mixtures Prediction Challenge 2025 - Task 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5938d987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submitterid</th>\n",
       "      <th>id</th>\n",
       "      <th>pearson_correlation</th>\n",
       "      <th>cosine</th>\n",
       "      <th>createdOn</th>\n",
       "      <th>createdOn_diff</th>\n",
       "      <th>pearson_rank</th>\n",
       "      <th>cosine_rank</th>\n",
       "      <th>final_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3516194</td>\n",
       "      <td>9756912</td>\n",
       "      <td>0.752053</td>\n",
       "      <td>0.176111</td>\n",
       "      <td>1754667730603</td>\n",
       "      <td>29868397</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3506852</td>\n",
       "      <td>9756908</td>\n",
       "      <td>0.730260</td>\n",
       "      <td>0.179923</td>\n",
       "      <td>1754667145501</td>\n",
       "      <td>30453499</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3550368</td>\n",
       "      <td>9756933</td>\n",
       "      <td>0.727444</td>\n",
       "      <td>0.184437</td>\n",
       "      <td>1754688407578</td>\n",
       "      <td>9191422</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    submitterid       id  pearson_correlation    cosine      createdOn  \\\n",
       "7       3516194  9756912             0.752053  0.176111  1754667730603   \n",
       "6       3506852  9756908             0.730260  0.179923  1754667145501   \n",
       "23      3550368  9756933             0.727444  0.184437  1754688407578   \n",
       "\n",
       "    createdOn_diff  pearson_rank  cosine_rank  final_rank  \n",
       "7         29868397           1.0          1.0         1.0  \n",
       "6         30453499           2.0          2.0         2.0  \n",
       "23         9191422           3.0          3.0         3.0  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submissions_df[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "11fa15ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_predictions = load_team_predictions(syn, submissions_df[1])\n",
    "gold_df = load_goldstandard(syn, 1)\n",
    "team_dfs = split_merged_to_team_dfs(team_predictions, gold_df, INDEX_COL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9a5aadce",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline, bootstrap_summary = baseline_and_bootstrap(\n",
    "    gold_df, team_dfs, INDEX_COL,\n",
    "    sample_frac=1.0, N=10000, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "79a08543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        team   pearson    cosine  rank_pearson  rank_cosine  average_rank\n",
      "1  3506852.0  0.046004  0.482542           1.0          2.0           1.5\n",
      "0  3516194.0  0.040188  0.417884           2.0          1.0           1.5\n",
      "2  3550368.0  0.034675  0.494238           3.0          3.0           3.0\n",
      "{'p_win': 0.4003, 'BF_odds': 0.667500422419536, 'N': 10000, 'rows_per_draw': 31, 'sample_frac': 1.0}\n"
     ]
    }
   ],
   "source": [
    "print(baseline)\n",
    "print(bootstrap_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c9796c",
   "metadata": {},
   "source": [
    "## Task 2 processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "444b5a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading files:   0%|          | 0.00/1.00 [00:00<?, ?B/s, syn68878940]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded syn68878940 to /Users/mdiaz/.synapseCache/484/161875484/SYNAPSE_TABLE_QUERY_161875484.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading files: 100%|██████████| 2.72k/2.72k [00:00<00:00, 29.0kB/s, syn68878940]\n"
     ]
    }
   ],
   "source": [
    "subview_id2 = SUBMISSION_VIEWS[\n",
    "        f\"Task {2}\"]\n",
    "submissions_df2 = select_final_round_submissions(\n",
    "        syn, subview_id2, \"Final Round DREAM Olfactory Mixtures Prediction Challenge 2025 - Task 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "de6e48ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submitterid</th>\n",
       "      <th>id</th>\n",
       "      <th>pearson_correlation</th>\n",
       "      <th>cosine</th>\n",
       "      <th>createdOn</th>\n",
       "      <th>createdOn_diff</th>\n",
       "      <th>pearson_rank</th>\n",
       "      <th>cosine_rank</th>\n",
       "      <th>final_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3506852</td>\n",
       "      <td>9756909</td>\n",
       "      <td>0.789749</td>\n",
       "      <td>0.133586</td>\n",
       "      <td>1754667217304</td>\n",
       "      <td>30381696</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3319559</td>\n",
       "      <td>9756951</td>\n",
       "      <td>0.789684</td>\n",
       "      <td>0.136842</td>\n",
       "      <td>1754695242525</td>\n",
       "      <td>2356475</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3550368</td>\n",
       "      <td>9756934</td>\n",
       "      <td>0.785382</td>\n",
       "      <td>0.137598</td>\n",
       "      <td>1754688452187</td>\n",
       "      <td>9146813</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   submitterid       id  pearson_correlation    cosine      createdOn  \\\n",
       "4      3506852  9756909             0.789749  0.133586  1754667217304   \n",
       "0      3319559  9756951             0.789684  0.136842  1754695242525   \n",
       "12     3550368  9756934             0.785382  0.137598  1754688452187   \n",
       "\n",
       "    createdOn_diff  pearson_rank  cosine_rank  final_rank  \n",
       "4         30381696           1.0          1.0         1.0  \n",
       "0          2356475           2.0          2.0         2.0  \n",
       "12         9146813           3.0          3.0         3.0  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submissions_df2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1caa596a",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_predictions2 = load_team_predictions(syn, submissions_df2[1])\n",
    "gold_df2 = load_goldstandard(syn, 2)\n",
    "team_dfs2 = split_merged_to_team_dfs(team_predictions2, gold_df2, INDEX_COL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62b77ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline2, bootstrap_summary2 = baseline_and_bootstrap(\n",
    "    gold_df2, team_dfs2, INDEX_COL,\n",
    "    sample_frac=1.0, N=10000, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19905a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      team   pearson    cosine  rank_pearson  rank_cosine  average_rank\n",
      "2  3550368 -0.000368  0.462619           1.0          2.0           1.5\n",
      "1  3319559 -0.004662  0.430524           2.0          1.0           1.5\n",
      "0  3506852 -0.006974  0.467343           3.0          3.0           3.0\n",
      "{'p_win': 0.4111, 'BF_odds': 0.6980811734066705, 'N': 10000, 'rows_per_draw': 130, 'sample_frac': 1.0}\n"
     ]
    }
   ],
   "source": [
    "print(baseline2)\n",
    "print(bootstrap_summary2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "synapse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
